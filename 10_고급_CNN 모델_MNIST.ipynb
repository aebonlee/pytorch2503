{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8XHHT99-Slm"
   },
   "source": [
    "### Chapter 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CNN(Convolutional Neural Network) : 합성곱 모델 MNIST**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaV6bKLx-Sls"
   },
   "source": [
    "> ## 학습 목표\n",
    "-   **CNN의 기본 개념 이해** : 합성곱 신경망(CNN)의 기본 원리와 구조를 이해하고, CNN이 이미지 데이터 처리에 효과적인 이유를 설명할 수 있다.\n",
    "    \n",
    "-   **합성곱 연산 및 필터 이해** : 합성곱 연산의 정의를 이해하고, 필터(커널)의 역할 및 작동 방식을 설명하며, 필터의 크기, 스트라이드, 패딩이 결과에 미치는 영향을 분석할 수 있다.\n",
    "    \n",
    "-   **CNN 아키텍처 구성 요소 이해** : CNN의 기본 구성 요소(합성곱 레이어, 풀링 레이어, 활성화 함수 등)의 역할을 이해하고, 이들이 합쳐져서 어떻게 특성 추출을 수행하는지를 설명할 수 있다.\n",
    "    \n",
    "-   **MNIST 데이터셋 처리 및 구현** : MNIST 데이터셋을 로드하고 전처리하는 방법을 이해하며, 파이토치를 사용하여 CNN 모델을 구현하는 능력을 배양할 수 있다.\n",
    "    \n",
    "-   **모델 훈련 및 성능 평가** : CNN 모델을 MNIST 데이터셋에 대해 훈련시키고, 다양한 성능 지표(정확도, 손실 값 등)를 활용하여 모델 성능을 평가하고 분석할 수 있다.\n",
    "    \n",
    "-   **하이퍼파라미터 조정** : CNN 모델 성능을 향상하기 위한 하이퍼파라미터 조정 기법(예: 레이어 수, 필터 수, 학습률 등)을 이해하고, 이를 통해 최적의 모델을 구하는 과정의 중요성을 인식할 수 있다.\n",
    "    \n",
    "-   **오버피팅 방지 및 일반화** : 오버피팅을 방지하기 위한 기술(예: 정규화, 드롭아웃 등)을 이해하고, CNN 모델이 새로운 데이터에 대해 일반화되도록 설계하는 방법을 배울 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10.1 CNN 개념**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### **CNN은 이미지 인식의 딥러닝 모델**입니다.\n",
    "- 데이터 처리 및 전처리 (Data Handling and Preprocessing)\n",
    "\n",
    "- **데이터셋(Dataset) 클래스 이해하기** : PyTorch의 torch.utils.data.Dataset 클래스를 사용하여 커스텀 데이터셋을 만드는 방법 이해하기\n",
    "\n",
    "- **데이터 로더**(DataLoader) : torch.utils.data.DataLoader를 이용해 배치(batch) 단위로 데이터를 로드하고, 학습 과정에서 데이터를 효율적으로 사용하는 방법 이해하기\n",
    "\n",
    "- **데이터 전처리**(Transformations) : 이미지나 텍스트 데이터의 전처리를 위해 torchvision.transforms를 사용하는 방법 이해하기\n",
    "\n",
    "- **합성곱 계층**(Convolutional Layer): 이미지나 시계열 데이터를 처리할 때 특징을 자동으로 추출합니다. \n",
    "\n",
    "   이미지에서 물체의 가장자리, 색상, 질감 등의 특징을 학습합니다.\n",
    "- **풀링 계층**(Pooling Layer): 데이터의 크기를 줄여서 계산을 효율적으로 만들고, 중요한 특징을 추출합니다.\n",
    "- **완전 연결 계층**(Fully Connected Layer): 추출된 특징을 기반으로 최종 출력을 예측합니다.\n",
    "- **CNN은 특히 이미지 분류, 객체 인식, 영상 분석 등과 같은 시각적 문제를 다루는 데 뛰어난 성능**을 보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.1 CNN의 기본 개념\n",
    "\n",
    "-   **합성곱 신경망(CNN)**: 이미지 인식 및 분류에 주로 사용되는 신경망 구조로, 픽셀 간의 공간적 관계를 고려하여 에지, 형태, 패턴 등의 특성을 추출하는 데 뛰어난 성능을 발휘합니다.\n",
    "-   **합성곱 연산**: 입력 이미지에 필터(또는 커널)를 적용하여 특징 맵을 생성하는 과정입니다. 필터는 이미지에서 특정 특징을 추출합니다.\n",
    "-   **활성화 함수**: 비선형성을 도입하여 모델의 표현력을 높이는 함수로, 일반적으로 ReLU(ReLU6) 또는 Sigmoid 등이 사용됩니다.\n",
    "-   **풀링 레이어**: 특징 맵을 다운샘플링하여 계산량을 줄이고, 주요 특징을 유지하는 역할을 합니다. 일반적으로 Max Pooling이 많이 사용됩니다.\n",
    "\n",
    "### 10.1.2 MNIST 데이터셋\n",
    "- 인공지능 연구의 권위자 Yann LeCun 교수가 만든 학습용 문제 (Convolutional Neural Networks(CNN, 합성곱 신경망)의 창시자)\n",
    "-   **MNIST(Modified National Institute of Standards and Technology)란 : 손으로 쓴 숫자(0~9)의 이미지 데이터셋으로, 28x28픽셀(입력층 뉴런 784개, 출력층 뉴런, 10개)의 그레이스케일 타입의 이미지로 구성되어 있습니다. 총 70,000개의 샘플로, 학습용 데이터 60,000개, 테스트용 데이터 10,000개가 있습니다.\n",
    "-   **데이터 전처리**: MNIST 데이터셋을 사용할 때, 이미지를 정규화(0~1 사이로 조정), 리사이즈(필요 시), 텐서로 변환하는 등의 전처리 과정을 포함합니다.\n",
    "\n",
    "### 10.1.3 CNN 구조와 구성요소\n",
    "\n",
    "-   **입력 레이어**: MNIST 데이터의 각 이미지를 입력하는 레이어입니다.\n",
    "-   **합성곱 레이어**: 필터를 사용하여 이미지에서 특징 맵을 생성합니다.\n",
    "-   **풀링 레이어**: 특징 맵의 크기를 줄이고, 가장 중요한 정보를 유지합니다.\n",
    "-   **드롭아웃 레이어**: 과적합을 방지하기 위해 랜덤으로 뉴런을 비활성화하는 레이어입니다.\n",
    "-   **완전 연결 레이어(FC)**: 최종 클래스 확률을 예측하기 위해 모든 뉴런이 연결된 레이어입니다.\n",
    "-   **출력 레이어**: 10개의 뉴런(0~9 숫자)에 대한 확률을 출력하는 레이어입니다.\n",
    "\n",
    "### 10.1.4 파이토치를 이용한 CNN 구현 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 필요한 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch: 파이토치의 핵심 라이브러리입니다. (torch 2.4.0, torchvision 0.19.0 사용)\n",
    "- torch.nn: 신경망 구축에 필요한 모듈을 제공합니다.\n",
    "- torch.optim: 다양한 옵티마이저(모델의 가중치를 업데이트하는 알고리즘)를 제공합니다.\n",
    "- torchvision: 데이터셋 로딩 및 변환에 유용한 라이브러리입니다.\n",
    "- torch.nn.functional: 다양한 신경망 함수(예: 활성화 함수, 풀링 등)를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) CNN 모델 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SimpleCNN`: CNN 모델 클래스를 정의합니다. `nn.Module`을 상속받아야 하며, 모델의 층을 정의하는 `__init__` 메소드를 포함합니다.\n",
    "\n",
    "-   `self.conv1`: 첫 번째 합성곱 층. 입력 채널 1(흑백 이미지), 출력 채널 32. 커널 사이즈는 3x3.\n",
    "-   `self.pool`: 풀링 층. 2x2 크기로 다운샘플링.\n",
    "-   `self.conv2`: 두 번째 합성곱 층. 입력 채널 32, 출력 채널 64.\n",
    "-   `self.fc1`: 첫 번째 완전 연결 층(FC). 입력 차원은 `64 * 7 * 7`, 출력 차원은 128.\n",
    "-   `self.fc2`: 두 번째 완전 연결 층(FC). 출력 차원은 10으로, 각 뉴런이 0~9 숫자에 해당합니다.\n",
    "-   `self.dropout`: 드롭아웃 층으로, 과적합 방지를 위해 일정 확률(50%)로 뉴런을 비활성화 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 순전파(Forward pass) 메소드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`forward`: 입력 데이터가 모델을 통과하며 처리되는 과정을 정의합니다.\n",
    "\n",
    "-   `self.conv1(x)`: 입력 `x`에 첫 번째 합성곱 층을 적용.\n",
    "-   `F.relu`: 활성화 함수(ReLU)를 통해 비선형성을 도입.\n",
    "-   `self.pool`: 풀링을 통해 특성 맵의 크기를 줄임.\n",
    "-   `x.view(-1, 64 * 7 * 7)`: 1차원으로 변환하여 완전 연결 층에 입력 가능하게 만듭니다.\n",
    "-   마지막 두 줄은 첫 번째 완전 연결 층을 거치고 드롭아웃을 적용한 후 두 번째 완전 연결 층을 거침."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) 데이터셋 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST('.', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `transforms`: 데이터 전처리를 정의합니다. 데이터를 텐서로 변환하고 정규화.\n",
    "-   `datasets.MNIST`: MNIST 데이터셋을 로드합니다.\n",
    "-   `DataLoader`: 데이터셋을 배치로 나누어 훈련할 수 있게 해줍니다. 여기서 `batch_size=64`는 한 번에 64개의 샘플을 사용하며, `shuffle=True`는 데이터를 무작위로 섞습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) 모델, 손실 함수 및 옵티마이저 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   모델 인스턴스를 생성합니다.\n",
    "-   `criterion`: 손실 함수로는 교차 엔트로피 손실 사용.\n",
    "-   `optimizer`: Adam 옵티마이저를 사용하여 모델의 가중치를 업데이트합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0961\n",
      "Epoch [2/5], Loss: 0.0312\n",
      "Epoch [3/5], Loss: 0.0656\n",
      "Epoch [4/5], Loss: 0.0543\n",
      "Epoch [5/5], Loss: 0.0670\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# ... (데이터 로더 및 기타 설정)\n",
    "\n",
    "# 모델, 손실 함수, 옵티마이저 정의\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # 여기에 합성곱 계층, 활성화 함수 등을 추가합니다.\n",
    "        # 예시:\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc = nn.Linear(16 * 14 * 14, 10)  # 출력 크기에 맞게 조정\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 여기에 순전파 연산을 정의합니다.\n",
    "        # 예시:\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)  # 완전히 연결된 계층을 위한 크기 조정\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(5):  # 에포크 수\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()  # 기울기 초기화\n",
    "\n",
    "        outputs = model(images)  # 순전파\n",
    "\n",
    "        loss = criterion(outputs, labels)  # 손실 계산\n",
    "\n",
    "        loss.backward()  # 역전파\n",
    "\n",
    "        optimizer.step()  # 가중치 업데이트\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/5], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `for epoch in range(5)`: 5 에포크 동안 학습을 수행합니다.\n",
    "-   각 배치에서:\n",
    "    \n",
    "    -   `optimizer.zero_grad()`: 기울기를 초기화합니다.\n",
    "    -   `model(images)`: 순전파를 통해 예측값을 얻습니다.\n",
    "    -   `criterion(outputs, labels)`: 손실을 계산합니다.\n",
    "    -   `loss.backward()`: 역전파를 통해 기울기를 계산합니다.\n",
    "    -   `optimizer.step()`: 가중치를 업데이트합니다.\n",
    "    \n",
    "-   마지막으로 에포크마다 손실 값을 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `전체 소스`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0953\n",
      "Epoch [2/5], Loss: 0.0474\n",
      "Epoch [3/5], Loss: 0.0455\n",
      "Epoch [4/5], Loss: 0.0377\n",
      "Epoch [5/5], Loss: 0.1607\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# CNN 모델 클래스 정의\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) #'F'를 사용할 수 있도록 import 추가\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 데이터셋 로드 및 전처리\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST('.', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 모델, 손실 함수 및 옵티마이저 정의\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 훈련\n",
    "for epoch in range(5):  # 에포크 수\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()  # 기울기 초기화\n",
    "        outputs = model(images)  # 순전파\n",
    "        loss = criterion(outputs, labels)  # 손실 계산\n",
    "        loss.backward()  # 역전파\n",
    "        optimizer.step()  # 가중치 업데이트\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/5], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 에포크 손실 해석\n",
    "\n",
    "1.  **Epoch \\[1/5\\], Loss: 0.0351**: 첫 번째 에포크에서 손실이 0.0351로 시작했으며, 모델이 초기적으로 잘 적합하고 있다는 신호입니다.\n",
    "    \n",
    "2.  **Epoch \\[2/5\\], Loss: 0.0648**: 두 번째 에포크에서 손실이 증가해 0.0648이 되었습니다. 이는 모델이 학습 도중 일시적으로 변동성을 보이고 있음을 나타냅니다.\n",
    "    \n",
    "3.  **Epoch \\[3/5\\], Loss: 0.0187**: 세 번째 에포크에서 손실이 크게 감소하여 0.0187로 나타났습니다. 모델이 효과적으로 학습하고 있음을 보여줍니다.\n",
    "    \n",
    "4.  **Epoch \\[4/5\\], Loss: 0.0079**: 네 번째 에포크에서 손실은 0.0079로 매우 낮아졌으며, 모델이 훈련 데이터에 대해 매우 잘 적합하고 있다는 것을 나타냅니다.\n",
    "    \n",
    "5.  **Epoch \\[5/5\\], Loss: 0.1285**: 마지막 다섯 번째 에포크에서 손실이 0.1285로 크게 증가했습니다. 이는 모델이 과적합되고 있거나 학습이 불안정해졌음을 시사합니다.\n",
    "    \n",
    "\n",
    "※ 전반적으로 모델은 3, 4 에포크 동안 매우 잘 학습되었으나, 마지막 에포크에서 손실이 급격히 증가하여 과적합의 위험이 있음을 나타냅니다. \n",
    "\n",
    "필요한 경우 정규화 기법이나 드롭아웃을 적용하여 과적합을 방지하는 방안을 고려할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5\\. 모델 평가 및 성능 지표\n",
    "\n",
    "-   **정확도(Accuracy)**: 모델의 예측이 실제 정답과 일치하는 비율로, MNIST에서는 높은 정확도가 기대됩니다.\n",
    "-   **혼돈 행렬(Confusion Matrix)**: 각 클래스에 대한 True Positive, False Positive, False Negative 등을 시각적으로 보여 주어 모델 성능을 평가할 수 있습니다.\n",
    "\n",
    "※ 학습 예시는 CNN의 구조와 동작 방식에 대한 이해를 높이기 위해 구분 설명하였습니다. 이 과정을 통해 기본적인 CNN을 통해 MNIST 데이터셋을 분류하는 단계부터 각 단계를 명확하게 설명하였고 응용 프로그램으로 손글씨 숫자 MNIST 모델을 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10.2 손글씨 숫자 MNIST**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 손글씨 숫자 데이터셋인 MNIST를 사용하여 딥러닝 모델을 구현합니다. \n",
    "- 이 데이터셋은 다양한 딥러닝 프레임워크에서 쉽게 접근할 수 있어 학습용으로 많이 쓰입니다. \n",
    "- **훈련 이미지 세트 60,000개, 테스트 세트 10,000개, 이미지 크기 28x28 픽셀의 회색조 이미지, 클래스 수 0~9까지의 총 10개 숫자 클래스**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **TensorFlow와 Keras를 사용하여 간단한 Convolutional Neural Network (CNN) 모델을 구현하는 방법으로 손글씨 숫자 MNIST를 학습합니다.**\n",
    "\n",
    "- **데이터 로드 및 전처리** : MNIST 데이터셋을 불러오고, 이미지를 모델에 입력하기 적합한 형태로 변환합니다.\n",
    "\n",
    "- **모델 구성** : CNN 모델을 설계합니다.\n",
    "\n",
    "- **모델 컴파일** : 손실 함수, 옵티마이저, 평가 지표를 지정합니다.\n",
    "\n",
    "- **모델 학습** : 훈련 데이터셋을 사용하여 모델을 학습시킵니다.\n",
    "\n",
    "- **모델 평가 및 예측** : 테스트 데이터셋으로 모델 성능을 평가합니다.\n",
    "\n",
    "※ Keras : https://keras.io/about/  머신러닝/딥러닝 플랫폼인 \"텐서플로우\"에서 실행되는 파이썬 API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## MNIST(Modified National Institute of Standards and Technology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1) 모듈 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "# from torch.autograd import Variable\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  **PyTorch 및 관련 모듈 임포트**: `torch`, `torch.nn`, `torch.optim` 등 다양한 PyTorch 모듈을 가져옵니다. 이는 텐서 조작, 신경망 구성 및 최적화에 사용됩니다.\n",
    "    \n",
    "2.  **데이터셋과 변환**: `datasets`와 `transforms`는 이미지 데이터셋을 다루고 전처리하는 데 필요합니다. 일반적으로 이미지 크기 조정, 정규화 등을 수행하기 위해 사용됩니다.\n",
    "    \n",
    "3.  **시각화**: `matplotlib.pyplot`를 임포트하여 학습 결과나 데이터 시각화를 위한 플롯을 생성할 수 있습니다. `%matplotlib inline`은 Jupyter 노트북에서 그래프를 인라인으로 표시하게 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2) 분석 환경 설정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device is cuda\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print ('Current cuda device is', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU 사용 가능 여부를 확인하고, 사용할 장치를 설정합니다.\n",
    "\n",
    "1.  `is_cuda = torch.cuda.is_available()`: CUDA(GPU) 사용 가능 여부를 체크합니다.\n",
    "2.  `device = torch.device('cuda' if is_cuda else 'cpu')`: CUDA가 가능하면 GPU(`cuda`), 그렇지 않으면 CPU(`cpu`)를 설정합니다.\n",
    "3.  `print('Current cuda device is', device)`: 현재 사용 중인 장치를 출력합니다.\n",
    "\n",
    "즉, 딥러닝 연산을 위한 최적의 장치를 선택하는 과정입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3) Hyper-parameter 지정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "learning_rate = 0.0001\n",
    "epoch_num = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝 모델의 훈련에 사용되는 하이퍼파라미터를 설정하는 부분으로 모델 훈련의 성능을 결정합니다. \n",
    "\n",
    "-   **batch\\_size = 50**: 한 번의 학습에서 사용할 데이터 샘플의 수를 50으로 설정, 모델이 한 번의 업데이트를 진행하는 데 사용하는 데이터의 양 결정\n",
    "-   **learning\\_rate = 0.0001**: 모델이 가중치를 업데이트하는 속도를 결정\n",
    "    - learning rate가 클수록 빠르게 학습하지만 불안정해지고, 작을수록 안정적이지만 학습 속도가 느려지는 trade-off가 존재함.\n",
    "    - learning rate에 따라 **발산**하는 결과를 가져올 수 있음.\n",
    "    - 모델과 데이터에 따라 최적의 learning rate는 달라질 수 있음. 예시로 0.0001 ~ 0.1은 다음과 같음.\n",
    "    - **0.1** : 상대적으로 큰 값으로, 모델이 빠르게 가중치를 업데이트하는 것으로 큰 learning rate는 초기 훈련 속도를 높일 수 있지만, 너무 크면 학습 과정에서 최적점에 수렴하지 않고, 손실함수의 값을 증가시키거나 무한히 커질 수 있음.\n",
    "    - **0.01** :  0.1보다는 안정적이고, 학습 속도는 빠르지만, 여전히 비효율적인 경우가 있을 수 있으며, 발산할 가능성은 줄어듬.\n",
    "    - **0.001** : 대부분의 경우에 적절한 learning rate로 간주하는 값, 안정적이고 효과적인 학습을 가능하게 하며, 손실 함수의 최소값에 더 잘 수렴할 수 있음.\n",
    "    - **0.0001** : 매우 작은 값으로, 학습이 매우 신중하게 이루어지기에 초기에는 느리게 진행되지만, 세밀한 조정이 가능해 특정 문제에서는 더 나은 성능을 보여줄 수 있음.(단, 학습이 지나치게 느려지기도 함)\n",
    "\n",
    "    ※  **발산이란?** - 학습속도에 따라 손실이 증가, 비선형성모델에서는 학습이 불안정, 부적절한 초기값으로 학습이 잘못됨, 데이터에 노이즈가 생기거나 이상치가 많으면 잘못된 학습을 하여 손실 값을 증가시키고 매우 비효율적으로 진행됨으로 모델이 필요하지 않게 됨. 이에, 적절한 learning rate를 설정하거나 다른 최적화 기법을 사용해야 하는 경우가 생김.\n",
    "\n",
    "-   **epoch\\_num = 15**: 전체 데이터셋을 15번 반복 학습, 각 epoch마다 모델은 데이터셋에 있는 모든 샘플을 한 번씩 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4) MNIST 데이터 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training data:  60000\n",
      "number of test data:  10000\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(root = './data', train = True, download = True, transform = transforms.ToTensor()) \n",
    "# 훈련 데이터셋 호출, 데이터를 텐서 형식으로 변환.\n",
    "test_data = datasets.MNIST(root = './data', train = False, transform = transforms.ToTensor())  \n",
    "# 테스트 데이터셋 호출, 데이터를 텐서 형식으로 변환.\n",
    "\n",
    "print('number of training data: ', len(train_data))\n",
    "# 훈련 데이터의 개수(60,000)를 출력\n",
    "print('number of test data: ', len(test_data))\n",
    "#테스트 데이터의 개수(10,000)를 출력\n",
    "\n",
    "# 코드 실행 시 MNIST 데이터셋이 자동으로 다운로드되고, 해당 경로에 압축이 풀리는 과정은 다음과 같습니다.\n",
    "\n",
    "# Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n",
    "# 9920512it [00:01, 5592512.82it/s]                                                                                      \n",
    "# Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
    "# Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
    "# 32768it [00:00, 66241.35it/s]                                                                                          \n",
    "# Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
    "# Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
    "# 1654784it [00:01, 1214690.45it/s]                                                                                      \n",
    "# Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
    "# Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
    "# 8192it [00:00, 19414.34it/s]                                                                                           \n",
    "# Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
    "# Processing...\n",
    "# Done!\n",
    "# number of training data:  60000\n",
    "# number of test data:  10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNIST 손글씨 숫자 데이터를 사용할 준비완료**\n",
    "- Training Data Count: 총 60,000개의 훈련 데이터\n",
    "- Testing Data Count: 총 10,000개의 테스트 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5) MNIST 데이터 확인하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "# 데이터 가져오기 : MNIST 훈련 데이터셋에서 첫 번째 이미지와 그에 해당하는 레이블(숫자) 가져오기\n",
    "\n",
    "plt.imshow(image.squeeze().numpy(), cmap = 'gray') # 이미지 시각화\n",
    "plt.title('label : %s' % label) # labal : train_data[0] 제목 출력\n",
    "plt.show() # 이미지를 화면에 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **6) Mini-Batch 구성하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name            | type                      | size\n",
      "Num of Batch    |                           | 1200\n",
      "first_batch     | <class 'list'>            | 2\n",
      "first_batch[0]  | <class 'torch.Tensor'>    | torch.Size([50, 1, 28, 28])\n",
      "first_batch[1]  | <class 'torch.Tensor'>    | torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, \n",
    "                                        batch_size = batch_size, shuffle = True)\n",
    "# 훈련 데이터셋을 배치 크기(batch_size)에 맞춰 불러오며, 데이터를 섞어서(shuffle = True) 무작위로 배치를 생성\n",
    "test_loader  = torch.utils.data.DataLoader(dataset = test_data, \n",
    "                                        batch_size = batch_size, shuffle = True)\n",
    "# 테스트 데이터셋도 동일하게 무작위로 배치를 생성\n",
    "\n",
    "first_batch = train_loader.__iter__().__next__()\n",
    "# 훈련 데이터 로더에서 첫 배치\n",
    "\n",
    "print('{:15s} | {:<25s} | {}'.format('name', 'type', 'size'))\n",
    "\n",
    "print('{:15s} | {:<25s} | {}'.format('Num of Batch', '', len(train_loader)))\n",
    "# 전체 배치의 수 (1200)입니다. (60,000개의 데이터를 배치 크기 50으로 나눈 수)\n",
    "\n",
    "print('{:15s} | {:<25s} | {}'.format('first_batch', str(type(first_batch)), len(first_batch)))\n",
    "# 첫 번째 배치의 타입이 리스트(<class 'list'>)이며, 두 개의 요소(이미지와 레이블)를 포함\n",
    "\n",
    "print('{:15s} | {:<25s} | {}'.format('first_batch[0]', str(type(first_batch[0])), first_batch[0].shape))\n",
    "# 첫 번째 배치에 포함된 이미지의 타입은 torch.Tensor이며, 크기는 [50, 1, 28, 28]입니다. 이는 50개의 28x28 크기 회색조 이미지(1채널)를 의미\n",
    "\n",
    "print('{:15s} | {:<25s} | {}'.format('first_batch[1]', str(type(first_batch[1])), first_batch[1].shape))\n",
    "# 첫 번째 배치에 포함된 레이블의 타입도 torch.Tensor이며, 크기는 [50]입니다. 이는 50개의 레이블(숫자)을 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 출력 결과는 모델이 훈련에 사용할 준비가 되었고, 각 배치에서 가져오는 데이터의 구조를 보기위해 출력 설정.\n",
    "- 총 1200개의 배치가 있으며, 각 배치마다 50개의 이미지와 1개 이미지는 28*28 픽셀 크기라는 것을 확인 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **7) CNN 구조 설계하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "    # 합성곱 레이어 설정\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1) \n",
    "        # conv1: 입력 채널 1, 필터 32개, 필터 크기 3x3\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        # conv2: 입력 채널 32, 필터 64개, 필터 크기 3x3\n",
    "        \n",
    "    # 드롭아웃 레이어 설정\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        # dropout1: 25% 확률로 드롭아웃 적용 (2D)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        # dropout2: 50% 확률로 드롭아웃 적용 (2D)\n",
    "        \n",
    "    # 완전 연결층 설정\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        # fc1: 9216 입력, 128 출력\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        # fc2: 128 입력, 10 출력 (10개의 클래스에 대한 결과)\n",
    "\n",
    "#  입력 데이터를 처리하여 클래스 확률을 반환\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # conv1을 통해 합성곱 연산을 수행\n",
    "        x = F.relu(x) # ReLU 활성화 함수 적용\n",
    "        x = self.conv2(x) # conv2를 통해 또 다른 합성곱 연산 수행\n",
    "        x = F.relu(x) # ReLU 활성화 함수 적용\n",
    "        x = F.max_pool2d(x, 2) # 2x2 최대 풀링(max pooling) 수행\n",
    "        x = self.dropout1(x) # 드롭아웃(dropout) 레이어 dropout1 적용\n",
    "        x = torch.flatten(x, 1) # 텐서를 1차원으로 평탄화(flatten)\n",
    "        x = self.fc1(x) # 완전 연결층 fc1에 전달\n",
    "        x = F.relu(x) # 재차 ReLU 활성화 함수 적용\n",
    "        x = self.dropout2(x) # 드롭아웃 레이어 dropout2 적용\n",
    "        x = self.fc2(x) # 마지막 완전 연결층 fc2에 전달\n",
    "        output = F.log_softmax(x, dim=1) \n",
    "        # 소프트맥스(log_softmax) 함수로 출력 확률 계산\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`입력 이미지를 분류하기 위한 CNN 모델`\n",
    "- PyTorch를 사용하여 CNN(Convolutional Neural Network)을 정의하는 클래스로 MNIST 데이터셋과 같은 이미지 분류 작업에 적합한 구조 설계\n",
    "- 전방향 전파 :\n",
    "  - 두 개의 합성곱 및 ReLU 활성화.\n",
    "  - 최대 풀링을 적용.\n",
    "  - 드롭아웃 후 텐서를 평탄화.\n",
    "  - 두 개의 완전 연결층을 통과하며 ReLU 및 드롭아웃 적용.\n",
    "  - 최종 출력으로 소프트맥스 로그를 반환."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- relu 활성화 함수  (0 이상의 값만 선형적으로 표시, 0 이하는 0으로)\n",
    "\n",
    "    https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n",
    "\n",
    "\n",
    "- softmax 활성화 함수 (벡터값을 확률 분포로 변환하며, 주로 분류신경망의 마지막 계층에 사용)\n",
    "\n",
    "    https://en.wikipedia.org/wiki/Softmax_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **8) Optimizer 및 손실함수 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CNN 모델을 초기화하고 훈련 설정을 구성` : **모델 초기화와 훈련 프로세스에 필요한 최적화 및 손실 함수 설정**\n",
    "\n",
    "1.  **모델 초기화**: `model = CNN().to(device)` - CNN 모델을 생성하고, 지정된 장치(`device`, 예: GPU 또는 CPU)로 이동\n",
    "\n",
    "2.  **옵티마이저 설정**: `optimizer = optim.Adam(model.parameters(), lr=learning_rate)`\n",
    "    - Adam 옵티마이저를 사용하여 모델의 파라미터를 최적화, 학습률(`learning_rate`)은 미리 정해진 값\n",
    "\n",
    "3.  **손실 함수 설정**: `criterion = nn.CrossEntropyLoss()` \n",
    "    - 다중 클래스 분류 문제를 위한 손실 함수로 교차 엔트로피 손실 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **9) 설계한 CNN 모형 확인하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`설계한 CNN 모형 확인하기` : CNN 모델의 구성 및 훈련 과정으로 높은 정확도로 훈련되었고, 손실이 감소함.\n",
    "\n",
    "1.  **장치 및 데이터 수** : CUDA 장치 사용 중 (GPU에서 실행), 훈련 데이터 60,000개, 테스트 데이터 10,000개.\n",
    "    \n",
    "2.  **배치 정보** :\n",
    "    \n",
    "    -   총 1,200개의 배치가 있으며, 각 배치의 크기는 50\n",
    "    -   첫 번째 배치의 입력 텐서는 크기 `[50, 1, 28, 28]` (50개의 28x28 흑백 이미지)\n",
    "    -   첫 번째 배치의 레이블 텐서는 크기 `[50]`\n",
    "    \n",
    "3.  **모델 구조** : 두 개의 합성곱 레이어, 두 개의 드롭아웃 레이어, 두 개의 완전 연결층이 정의\n",
    "    \n",
    "4.  **훈련 손실** : 각 1,000 스텝마다 훈련 손실이 출력되며, 손실이 지속적으로 감소하는 추세를 보임\n",
    "    \n",
    "5.  **테스트 정확도** : 테스트 세트에서 99.01%의 정확도를 달성\n",
    "    \n",
    "6.  **텐서 출력** : 마지막 줄의 텐서는 교육 동안 학습된 모든 예제가 올바르게 분류\n",
    "    \n",
    "7.  **에포크 정보** : 모델이 5 에포크 동안 훈련되었고, 최종 에포크에서 손실 값은 0.1285"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **10) 모델 학습하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:1538: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 1000\tLoss: 0.235\n",
      "Train Step: 2000\tLoss: 0.161\n",
      "Train Step: 3000\tLoss: 0.189\n",
      "Train Step: 4000\tLoss: 0.052\n",
      "Train Step: 5000\tLoss: 0.065\n",
      "Train Step: 6000\tLoss: 0.055\n",
      "Train Step: 7000\tLoss: 0.071\n",
      "Train Step: 8000\tLoss: 0.067\n",
      "Train Step: 9000\tLoss: 0.038\n",
      "Train Step: 10000\tLoss: 0.051\n",
      "Train Step: 11000\tLoss: 0.022\n",
      "Train Step: 12000\tLoss: 0.045\n",
      "Train Step: 13000\tLoss: 0.045\n",
      "Train Step: 14000\tLoss: 0.006\n",
      "Train Step: 15000\tLoss: 0.049\n",
      "Train Step: 16000\tLoss: 0.022\n",
      "Train Step: 17000\tLoss: 0.042\n",
      "Train Step: 18000\tLoss: 0.017\n"
     ]
    }
   ],
   "source": [
    "model.train() # 모델 훈련 모드 설정: model.train()으로 모델을 학습 모드로 전환\n",
    "i = 1\n",
    "for epoch in range(epoch_num): # 훈련 데이터를 배치 단위로 처리\n",
    "    for data, target in train_loader: #  데이터를 가져오고 GPU 장치로 이동\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad() \n",
    "        #기울기 초기화: optimizer.zero_grad()로 이전 배치의 기울기를 초기화\n",
    "        \n",
    "        output = model(data) # 모델 예측: 입력 데이터에 대한 예측 수행\n",
    "        loss = criterion(output, target) # 예측과 실제 레이블 간의 손실 계산\n",
    "        loss.backward() # 역전파 및 옵티마이즈 : 기울기 계산\n",
    "        optimizer.step() # 가중치 업데이트\n",
    "        \n",
    "        if i % 1000 == 0: # 주기적 손실 출력 : 1,000 스텝마다 현재 손실 출력\n",
    "            print('Train Step: {}\\tLoss: {:.3f}'.format(i, loss.item()))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련 데이터 : 60,000개, 테스트 데이터 10,000개.\n",
    "- 모델 구조 : 두 개의 합성곱 레이어와 드롭아웃 레이어, 완전 연결층.\n",
    "- 손실 감소 : 훈련 스텝에 따라 손실이 줄어드는 것이 관찰되며, 이는 모델이 점점 더 잘 학습하고 있음\n",
    "- 테스트 정확도 : 모델이 99.01%의 정확도로 테스트 데이터에서 좋은 성능\n",
    "- 텐서 출력 : 훈련 중 모든 예측이 올바르게 분류\n",
    "- 에포크 손실 : 5 에포크 동안 손실이 감소하다가 마지막 에포크에서 약간 증가하는 경향을 보임\n",
    "\n",
    "※ CNN 모델을 효과적으로 훈련시키고 높은 정확도를 기록함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **11) 모델 평가하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy: 99.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval() \n",
    "# 모델을 평가 모드로 전환, 드롭아웃 등 훈련 전용 레이어의 동작을 비활성화\n",
    "\n",
    "correct = 0 # correct 변수를 0으로 초기화하여 올바르게 예측한 샘플 수 계산\n",
    "\n",
    "for data, target in test_loader:\n",
    "#     data, target = Variable(data, volatile=True), Variable(target)\n",
    "   \n",
    "    data = data.to(device) # 데이터 GPU로 이동\n",
    "    target = target.to(device)\n",
    "    \n",
    "    output = model(data) # 테스트 데이터에 대한 예측 결과 생성\n",
    "    prediction = output.data.max(1)[1] # 각 샘플에 대해 최대 확률인 클래스 선택\n",
    "    correct += prediction.eq(target.data).sum()\n",
    "    # 예측이 실제 레이블과 일치하는 경우를 계산하여 correct에 누적\n",
    "\n",
    "print('Test set: Accuracy: {:.2f}%'.format(100. * correct / len(test_loader.dataset))) # 전체 테스트 샘플에 대한 정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9900, device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- correct 변수가 tensor(9901, device='cuda:0')로 출력된 것은 모델이 9,901개의 테스트 샘플을 올바르게 분류한 것을 재확인 함.\n",
    "- 정확한 예측 수: 9901은 테스트 데이터셋에서 모델이 정확하게 예측한 클래스의 수이고, 10,000개의 테스트 샘플 중 9,901개가 정답과 일치한 것을 알려줌\n",
    "- 장치 정보 : device='cuda:0'는 이 텐서가 GPU에서 계산되었다는 것을 의미(훈련과 예측이 GPU에서 수행되어 성능 향상됨)\n",
    "- 결론적으로, 모델은 테스트 세트에 대해 약 99.01%의 정확도를 기록했으며, 매우 높은 성능이고, 이 값은 후속적으로 전체 테스트 데이터셋에 대한 정확도를 계산하는 데 사용될 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.eq(target.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prediction.eq(target.data)의 결과가 **tensor([True, True, True, ..., True], device='cuda:0')로 출력된 것은 모델의 예측(prediction)이 모든 타겟(target) 라벨과 일치**함을 재확인 함.\n",
    "- 결과 형태는 출력 텐서의 각 요소가 True 또는 False로 구성된 1D 텐서(1차원 텐서 : 단일 축(차원)으로 구성된 배열 형태의 데이터 구조)라는 것이고, 이 텐서의 각 요소는 해당 인덱스의 예측 결과가 정답 레이블과 일치하는지를 나타내 준 것임.\n",
    "- 모든 예측이 정확하게 계산되었고 모든 요소가 True로 표시되어 있으므로, 모델이 평가한 모든 샘플(여기서는 50개 배치)의 예측 결과가 정답과 완전히 일치함을 의미함.\n",
    "- 장치 정보는 **device='cuda:0'으로 이 텐서가 GPU에서 계산**되었음을 나타내며, 이는 GPU를 사용하여 연산이 수행되었음을 확인시켜 주는 것임.\n",
    "- 결론적으로, 이 출력은 해당 테스트 배치의 모든 예측이 정답으로 확인되었음을 나타내며, 높은 정확도로 모델이 작동하고 있음을 보여줌."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
